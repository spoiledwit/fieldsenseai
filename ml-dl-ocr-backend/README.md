# FS FieldSense AI Backend 

This FastAPI application combines YOLO object detection with a custom OCR model (ResNet + Transformer) to extract text from detected regions in an uploaded image.

## ğŸš€ Features

- ğŸ” Object detection using YOLO 
- ğŸ§  OCR using a ResNet + Transformer model 
- ğŸ“¦ FastAPI backend with CORS support
- ğŸ–¼ï¸ Upload an image and get detected regions + extracted text
- ğŸ” Merges overlapping bounding boxes using IoU


## ğŸ“¥ Download Pretrained Models

Before running the app, make sure the following models are downloaded and placed in the `models/` directory:

All model files can be downloaded from this shared Google Drive folder:

ğŸ‘‰ [Download Models Folder](https://drive.google.com/drive/folders/19Nf7hpAKAcoQYuVN3mRLf6EGsyVGbUnF?usp=sharing)

| Model Type              | File Name            |
|-------------------------|----------------------|
| YOLOv8 Detection Model  | `v11sbest.pt`        |
| OCR ResNet-Transformer  | `best_atm_model.pth` |

### ğŸ“ How to Download and Setup

1. Click the links above to download the model files.
2. Create a folder named `models/` in the root of the project if it doesnâ€™t exist.
3. Place the downloaded files inside the `models/` folder.

Your project directory should look like this:

## ğŸ“ Directory Structure

```
.
â”œâ”€â”€ main.py                  # FastAPI app entry point
â”œâ”€â”€ Dockerfile               # Docker build file
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ models/                  # Contains .pt and .pth model files
â”œâ”€â”€ text_recognizer/         # OCR model code
â”œâ”€â”€ .gitignore               # Ignored files/folders
â””â”€â”€ __pycache__/             # Python cache (ignored)
```

## ğŸ› ï¸ Requirements

Install dependencies with:

```bash
# Create virtual environment
python -m venv .env

# Activate virtual environment
# For Windows:
.env\Scripts\activate
# For macOS/Linux:
source .env/bin/activate

# Upgrade pip
pip install --upgrade "pip==22.*"

# Install required packages
pip install -r requirements.txt
```

Ensure you place the following files in the `models/` directory:

- `v11sbest.pt` â€” YOLO model for object detection
- `best_atm_model.pth` â€” OCR model

## ğŸ§ª Run Locally

```bash
uvicorn main:app --reload
```

Then access: [http://localhost:8000/docs](http://localhost:8000/docs) for Swagger UI.

## ğŸ³ Docker Usage

To build and run the app with Docker:

```bash
docker build -t ocr-yolo-app .
docker run -p 8000:8000 ocr-yolo-app
```

## ğŸ“¬ API Endpoint

### POST `/analyze`

Upload an image and receive text predictions for detected regions.

**Body**: `multipart/form-data` with image file

**Response**:
```json
{
  "results": [
    {
      "class_id": "Text",
      "bbox": [x1, y1, x2, y2],
      "confidence": 0.91,
      "text": "AB123456"
    },
    ...
  ]
}
```

## ğŸ”’ Notes

- CORS is enabled for all origins by default
- The app currently runs on CPU

---

**Author:** MSDS 23 Batch  
**License:** ITU